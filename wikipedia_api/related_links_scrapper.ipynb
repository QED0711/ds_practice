{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pymongo\n",
    "from copy import copy, deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_see_also(soup):\n",
    "    return soup.find(attrs={\"id\":\"See_also\"})\n",
    "\n",
    "\n",
    "def find_links(soup):\n",
    "    if soup.name == \"ul\":\n",
    "        return soup.find_all(\"li\")\n",
    "    \n",
    "    if soup.name == \"div\" and \" \".join(soup[\"class\"]) == \"div-col columns column-width\":\n",
    "        return soup.find_all(\"li\")\n",
    "    \n",
    "    return find_links(soup.find_next_sibling())\n",
    "\n",
    "\n",
    "def process_links(links):\n",
    "    hrefs = []\n",
    "    for link in links:\n",
    "        hrefs.append(\"https://en.wikipedia.org\" + link.find('a').get(\"href\"))\n",
    "    return tuple(hrefs)\n",
    "    \n",
    "    \n",
    "    \n",
    "def get_article_title(soup):\n",
    "    return soup.find(attrs={\"id\":\"firstHeading\"}).text\n",
    "    \n",
    "      \n",
    "def get_related_links(url):\n",
    "    resp = requests.get(url)\n",
    "    soup = BeautifulSoup(resp.content)\n",
    "    \n",
    "    title = get_article_title(soup)\n",
    "    \n",
    "    see_also = find_see_also(soup)\n",
    "    \n",
    "    if see_also:\n",
    "        links = find_links(see_also.find_parent())\n",
    "    else: \n",
    "        return None\n",
    "    \n",
    "    return {\n",
    "        \"title\": title,\n",
    "        \"url\": url,\n",
    "        \"links\": process_links(links)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Brain',\n",
       " 'url': 'https://en.wikipedia.org/wiki/Brain',\n",
       " 'links': ('https://en.wikipedia.org/wiki/Brain%E2%80%93computer_interface',\n",
       "  'https://en.wikipedia.org/wiki/Central_nervous_system_disease',\n",
       "  'https://en.wikipedia.org/wiki/List_of_neuroscience_databases',\n",
       "  'https://en.wikipedia.org/wiki/Neurological_disorder',\n",
       "  'https://en.wikipedia.org/wiki/Optogenetics',\n",
       "  'https://en.wikipedia.org/wiki/Outline_of_neuroscience')}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_related_links(\"https://en.wikipedia.org/wiki/Brain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keys import *\n",
    "\n",
    "class WikiScrapper:\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.data = []\n",
    "    \n",
    "    \n",
    "    def traverse_from(self, url, max_depth=3, max_nodes=100):\n",
    "        current = get_related_links(url)\n",
    "        queue = list(current['links'])\n",
    "        self.data = [current]\n",
    "        seen = {current[\"title\"]: True}\n",
    "        depth_count = 1\n",
    "                \n",
    "        while depth_count < max_depth:\n",
    "            queue_copy = queue.copy()\n",
    "            \n",
    "            for link in queue_copy:\n",
    "                try:\n",
    "                    current = get_related_links(queue.pop(0))\n",
    "                    \n",
    "                    if current:\n",
    "                        \n",
    "                        if seen.get(current['title']):\n",
    "                            continue\n",
    "                        \n",
    "                        seen[current['title']] = True\n",
    "                        \n",
    "                        queue += current['links']\n",
    "                        self.data.append(current)\n",
    "                        \n",
    "                        if max_nodes and len(self.data) == max_nodes:\n",
    "                            return self.data\n",
    "                        \n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            depth_count += 1\n",
    "            \n",
    "        return self.data\n",
    "        \n",
    "    \n",
    "    def to_dataframe(self):\n",
    "        return pd.DataFrame(self.data)\n",
    "    \n",
    "    def to_csv(self, file_name):\n",
    "        self.to_dataframe().to_csv(file_name, index=False)\n",
    "    \n",
    "    def add_ids(self):\n",
    "        data = deepcopy(self.data)\n",
    "        \n",
    "        for article in data:\n",
    "            article['_id'] = article['title']\n",
    "        return data\n",
    "    \n",
    "    def to_mlab(self):\n",
    "        \n",
    "        uri = f\"mongodb://{mlab_api['username']}:{mlab_api['password']}@ds261277.mlab.com:61277/wiki_scrapper\"\n",
    "        client = pymongo.MongoClient(uri)\n",
    "\n",
    "        db = client.get_default_database()\n",
    "\n",
    "        data_inserter = db[\"known_related\"]\n",
    "        \n",
    "        # add ids to our data for so we don't save duplicates of the same topic\n",
    "        # save to a new version so that we don't overwrite any of our other data\n",
    "        links_data = self.add_ids()\n",
    "\n",
    "        for article in links_data:\n",
    "            try:\n",
    "                data_inserter.insert_one(article)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scrapper = WikiScrapper()\n",
    "\n",
    "scrapper.traverse_from(\"https://en.wikipedia.org/wiki/Brain\", max_depth=3, max_nodes=None);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapper.to_mlab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapper.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
